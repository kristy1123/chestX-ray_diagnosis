{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e01ad92e",
   "metadata": {},
   "source": [
    "ì‚¬ìš© ëª¨ë¸ : EfficientNet-B0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbc1dc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e3cb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘: C:/project/lungX/CXR8/Data_Entry_processed_Final.csv\n",
      "ğŸ“Š Sampling Base Count (1 ratio): 11203\n",
      "ğŸ“Š No Finding Count (2 ratio): 22406\n",
      "âœ… Train Set Completed: 56015 images\n",
      "âœ… Test Set Completed : 41251 images\n",
      "ğŸš€ Device: cpu\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to C:\\Users\\KDT-31/.cache\\torch\\hub\\checkpoints\\efficientnet_b0_rwightman-7f5810bc.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20.5M/20.5M [05:05<00:00, 70.2kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Training Start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/3501 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "\n",
    "# =========================================================\n",
    "# [1] ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¶„í•  í•¨ìˆ˜ \n",
    "# =========================================================\n",
    "def prepare_datasets(csv_path, target_classes):\n",
    "    \"\"\"\n",
    "    csv_path: ë©”íƒ€ë°ì´í„° CSV ê²½ë¡œ\n",
    "    target_classes: ['No Finding', 'Disease_A', 'Disease_B', 'Disease_C'] ìˆœì„œ\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ“‚ ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘: {csv_path}\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # 1. ê° í´ë˜ìŠ¤ë³„ ë°ì´í„°í”„ë ˆì„ ì¶”ì¶œ\n",
    "    dfs = {}\n",
    "    for label in target_classes:\n",
    "        # í•´ë‹¹ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ëŠ” í–‰ í•„í„°ë§\n",
    "        dfs[label] = df[df['Finding Labels'].str.contains(label)]\n",
    "    \n",
    "    # 2. ë°ì´í„° ê°œìˆ˜ ê¸°ì¤€ì  ì„¤ì • (ê°€ì¥ ì ì€ ì§ˆë³‘ ë°ì´í„° ìˆ˜ ê¸°ì¤€)\n",
    "    # No Findingì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ì§ˆë³‘ë“¤ ì¤‘ ìµœì†Œ ë°ì´í„° ìˆ˜ í™•ì¸\n",
    "    disease_counts = [len(dfs[c]) for c in target_classes if c != 'No Finding']\n",
    "    if not disease_counts:\n",
    "        raise ValueError(\"ì§ˆë³‘ í´ë˜ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "    min_count = min(disease_counts)\n",
    "    \n",
    "    # 3. ë¹„ìœ¨ ì„¤ì • (No Finding 2 : ì§ˆë³‘ 1)\n",
    "    n_disease = min_count\n",
    "    n_no_finding = min_count * 2\n",
    "    \n",
    "    print(f\"ğŸ“Š Sampling Base Count (1 ratio): {n_disease}\")\n",
    "    print(f\"ğŸ“Š No Finding Count (2 ratio): {n_no_finding}\")\n",
    "    \n",
    "    # 4. ìƒ˜í”Œë§ (Train Set êµ¬ì„±)\n",
    "    train_fragments = []\n",
    "    for label in target_classes:\n",
    "        n_sample = n_no_finding if label == 'No Finding' else n_disease\n",
    "        \n",
    "        # ë°ì´í„°ê°€ ë¶€ì¡±í•  ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ n_sample ì¡°ì • (ì•ˆì „ì¥ì¹˜)\n",
    "        actual_count = len(dfs[label])\n",
    "        if actual_count < n_sample:\n",
    "            print(f\"âš ï¸ Warning: {label} ë°ì´í„° ë¶€ì¡± ({actual_count} < {n_sample}). ì „ì²´ ì‚¬ìš©.\")\n",
    "            n_sample = actual_count\n",
    "            \n",
    "        # ëœë¤ ìƒ˜í”Œë§\n",
    "        sampled = dfs[label].sample(n=n_sample, random_state=42)\n",
    "        train_fragments.append(sampled)\n",
    "        \n",
    "    # í•™ìŠµ ë°ì´í„° ë³‘í•© ë° ì„ê¸°\n",
    "    train_df = pd.concat(train_fragments)\n",
    "    train_df = shuffle(train_df, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    # 5. í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± (í•™ìŠµì— ì‚¬ìš©ë˜ì§€ ì•Šì€ ë‚˜ë¨¸ì§€ ë°ì´í„°)\n",
    "    # ì´ë¯¸ì§€ ì¸ë±ìŠ¤(íŒŒì¼ëª…)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì°¨ì§‘í•© ì—°ì‚°\n",
    "    train_filenames = set(train_df['Image Index'].values)\n",
    "    \n",
    "    # ì „ì²´ ë°ì´í„° ì¤‘ í•™ìŠµì— ì•ˆ ì“°ì¸ ê²ƒë§Œ í•„í„°ë§\n",
    "    test_df_all = df[~df['Image Index'].isin(train_filenames)]\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ì…‹ì—ì„œë„ ìš°ë¦¬ê°€ ê´€ì‹¬ ìˆëŠ” 4ê°œ í´ë˜ìŠ¤ ê´€ë ¨ ë°ì´í„°ë§Œ ë‚¨ê¹€ (í•„ìš” ì‹œ ìˆ˜ì • ê°€ëŠ¥)\n",
    "    condition = test_df_all['Finding Labels'].str.contains(target_classes[0])\n",
    "    for label in target_classes[1:]:\n",
    "        condition |= test_df_all['Finding Labels'].str.contains(label)\n",
    "        \n",
    "    test_df = test_df_all[condition].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"âœ… Train Set Completed: {len(train_df)} images\")\n",
    "    print(f\"âœ… Test Set Completed : {len(test_df)} images\")\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "# =========================================================\n",
    "# [2] ì „ëµ B (Masking & Cropping) Dataset í´ë˜ìŠ¤\n",
    "# =========================================================\n",
    "class LungMaskDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, mask_dir, classes, transform=None):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.classes = classes\n",
    "        self.df['labels_list'] = self.df['Finding Labels'].apply(lambda x: x.split('|'))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def apply_mask_strategy(self, img_path, mask_path):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if img is None: return None\n",
    "        # ë§ˆìŠ¤í¬ê°€ ì—†ìœ¼ë©´ ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "        if mask is None: return Image.fromarray(img).convert('RGB')\n",
    "        \n",
    "        # í¬ê¸° ë§ì¶”ê¸°\n",
    "        if img.shape != mask.shape:\n",
    "            mask = cv2.resize(mask, (img.shape[1], img.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "            \n",
    "        # 1. ë°°ê²½ ì œê±° (Masking)\n",
    "        masked_img = cv2.bitwise_and(img, img, mask=mask)\n",
    "        \n",
    "        # 2. í ì˜ì—­ Cropping\n",
    "        points = cv2.findNonZero(mask)\n",
    "        if points is not None:\n",
    "            x, y, w, h = cv2.boundingRect(points)\n",
    "            crop_img = masked_img[y:y+h, x:x+w]\n",
    "        else:\n",
    "            crop_img = masked_img\n",
    "            \n",
    "        return Image.fromarray(crop_img).convert('RGB')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        fname = row['Image Index']\n",
    "        \n",
    "        img_path = os.path.join(self.img_dir, fname)\n",
    "        mask_path = os.path.join(self.mask_dir, fname)\n",
    "        \n",
    "        image = self.apply_mask_strategy(img_path, mask_path)\n",
    "        \n",
    "        if image is None: # ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê²€ì€ ì´ë¯¸ì§€\n",
    "            image = Image.new('RGB', (224, 224))\n",
    "            \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # Multi-hot Labeling\n",
    "        label_vec = torch.zeros(len(self.classes), dtype=torch.float32)\n",
    "        for i, cls_name in enumerate(self.classes):\n",
    "            if cls_name in row['labels_list']:\n",
    "                label_vec[i] = 1.0\n",
    "                \n",
    "        return image, label_vec\n",
    "\n",
    "# =========================================================\n",
    "# [3] ëª¨ë¸ ë° í•™ìŠµ í•¨ìˆ˜\n",
    "# =========================================================\n",
    "def get_efficientnet_model(num_classes, device):\n",
    "    model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "    in_features = model.classifier[1].in_features\n",
    "    model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "    return model.to(device)\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, device, target_names):\n",
    "    model.eval()\n",
    "    all_targets = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.sigmoid(outputs)\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "    \n",
    "    all_targets = np.vstack(all_targets)\n",
    "    all_preds = np.vstack(all_preds)\n",
    "    \n",
    "    try:\n",
    "        auc = roc_auc_score(all_targets, all_preds, average='macro')\n",
    "    except:\n",
    "        auc = 0.0\n",
    "    return auc, all_targets, all_preds\n",
    "\n",
    "# =========================================================\n",
    "# [Main Execution Flow]\n",
    "# =========================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # --- ì„¤ì •ê°’ (ì‚¬ìš©ì ê²½ë¡œ ìˆ˜ì • í•„ìˆ˜) ---\n",
    "    RAW_IMG_DIR = \"D:/lung_xray/final_denoised\"          # ì›ë³¸ ì´ë¯¸ì§€ í´ë”\n",
    "    MASK_DIR = \"D:/lung_xray/final_contour_masks\" # ë§ˆìŠ¤í¬ í´ë”\n",
    "    CSV_PATH = \"C:/project/lungX/CXR8/Data_Entry_processed_Final.csv\"        # CSV íŒŒì¼ ê²½ë¡œ\n",
    "    \n",
    "    # 4ê°œ í´ë˜ìŠ¤ ì •ì˜\n",
    "    TARGET_CLASSES = ['No Finding', 'Infiltration', 'Effusion', 'Atelectasis'] \n",
    "    \n",
    "    BATCH_SIZE = 5 #GPUê°€ ì—†ì–´ì„œ... 10ì—ì„œ ë³€ê²½\n",
    "    EPOCHS = 5\n",
    "    LR = 1e-4\n",
    "    \n",
    "    # 1. ë°ì´í„° ë¶„í•  í•¨ìˆ˜ í˜¸ì¶œ (ì—¬ê¸°ì„œ NameError í•´ê²°!)\n",
    "    train_df, test_df = prepare_datasets(CSV_PATH, TARGET_CLASSES)\n",
    "    \n",
    "    # 2. DataLoader ì„¤ì •\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    train_ds = LungMaskDataset(train_df, RAW_IMG_DIR, MASK_DIR, TARGET_CLASSES, transform)\n",
    "    test_ds = LungMaskDataset(test_df, RAW_IMG_DIR, MASK_DIR, TARGET_CLASSES, transform)\n",
    "    \n",
    "    num_workers = min(8, multiprocessing.cpu_count())\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # 3. ëª¨ë¸ ì¤€ë¹„ ë° í•™ìŠµ\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"ğŸš€ Device: {device}\")\n",
    "    \n",
    "    model = get_efficientnet_model(len(TARGET_CLASSES), device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "    \n",
    "    print(\"ğŸš€ Training Start...\")\n",
    "    for epoch in range(EPOCHS):\n",
    "        loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        auc, _, _ = evaluate(model, test_loader, device, TARGET_CLASSES)\n",
    "        print(f\"Epoch [{epoch+1}/{EPOCHS}] Loss: {loss:.4f} | Test AUC: {auc:.4f}\")\n",
    "        \n",
    "    print(\"\\n[Final Report]\")\n",
    "    final_auc, y_true, y_pred = evaluate(model, test_loader, device, TARGET_CLASSES)\n",
    "    print(f\"Overall Macro AUC: {final_auc:.4f}\")\n",
    "    \n",
    "    for i, cls in enumerate(TARGET_CLASSES):\n",
    "        try:\n",
    "            cls_auc = roc_auc_score(y_true[:, i], y_pred[:, i])\n",
    "            print(f\" - {cls:<15} AUC: {cls_auc:.4f}\")\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0083200f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
